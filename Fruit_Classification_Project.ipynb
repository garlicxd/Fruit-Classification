{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garlicxd/Fruit-Classification/blob/automation/Fruit_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE5TzdybiHaZ"
      },
      "source": [
        "## Todo\n",
        "- [ ] patience for training - stopping after no improvement for several epochs\n",
        "- [ ] create graphs - store information while training\n",
        "- [ ] compare different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "805e28f2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Function Declarations\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import json\n",
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ==========================================\n",
        "# 1. Configuration\n",
        "# ==========================================\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        # Hardware Detection (CUDA / ROCm / CPU)\n",
        "        self.DEVICE = self._get_device()\n",
        "\n",
        "        # Dataset Paths\n",
        "        self.DATASET_FOLDER_PATH = \"./split_ttv_dataset_type_of_plants\"\n",
        "        self.BASE_TRAIN_DIR = os.path.join(self.DATASET_FOLDER_PATH, 'Train_Set_Folder')\n",
        "        self.BASE_VAL_DIR = os.path.join(self.DATASET_FOLDER_PATH, 'Validation_Set_Folder')\n",
        "        self.BASE_TEST_DIR = os.path.join(self.DATASET_FOLDER_PATH, 'Test_Set_Folder')\n",
        "\n",
        "        # Filtered Dataset Paths\n",
        "        self.BASE_FILTERED_DIR = './filtered_data'\n",
        "        self.FILTERED_TRAIN_DIR = os.path.join(self.BASE_FILTERED_DIR, 'train')\n",
        "        self.FILTERED_VAL_DIR = os.path.join(self.BASE_FILTERED_DIR, 'val')\n",
        "        self.FILTERED_TEST_DIR = os.path.join(self.BASE_FILTERED_DIR, 'test')\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.IMG_SIZE = (224, 224)\n",
        "        self.BATCH_SIZE = 32\n",
        "        self.LEARNING_RATE = 0.01\n",
        "        self.EPOCHS = 5\n",
        "        self.MAX_IMAGES_PER_CLASS_TRAIN = 1000\n",
        "        self.SHUFFLE_TRAINING = True\n",
        "\n",
        "        # Augmentation Toggle\n",
        "        self.IMG_AUGMENT = False\n",
        "\n",
        "        # Experiment Names & Saving\n",
        "        self.EXPERIMENT_NAME = \"with_augmented_images\" if self.IMG_AUGMENT else \"baseline_no_augmented_images\"\n",
        "        self.MODEL_SAVE_PATH = f'./resnet50_{self.EXPERIMENT_NAME}.pth'\n",
        "        self.HISTORY_SAVE_PATH = f'./history_{self.EXPERIMENT_NAME}.json'\n",
        "        self.CLASS_MAP_PATH = './class_mapping.json'\n",
        "\n",
        "        # Classes\n",
        "        self.CLASSES_TO_USE = [\n",
        "            \"aloevera\", \"banana\", \"bilimbi\", \"cantaloupe\", \"cassava\", \"coconut\",\n",
        "            \"corn\", \"cucumber\", \"curcuma\", \"eggplant\", \"galangal\", \"ginger\",\n",
        "            \"guava\", \"kale\", \"longbeans\", \"mango\", \"melon\", \"orange\", \"paddy\",\n",
        "            \"papaya\", \"peper chili\", \"pineapple\", \"pomelo\", \"shallot\", \"soybeans\",\n",
        "            \"spinach\", \"sweet potatoes\", \"tobacco\", \"waterapple\", \"watermelon\"\n",
        "        ]\n",
        "        self.NUM_CLASSES = len(self.CLASSES_TO_USE)\n",
        "\n",
        "    def _get_device(self):\n",
        "        \"\"\"Detects if CUDA (Nvidia) or ROCm (AMD) is available.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            device_name = torch.cuda.get_device_name(0)\n",
        "            if hasattr(torch.version, 'hip') and torch.version.hip:\n",
        "                print(f\"✅ ROCm (AMD) detected: {device_name}\")\n",
        "            else:\n",
        "                print(f\"✅ CUDA (NVIDIA) detected: {device_name}\")\n",
        "            return torch.device(\"cuda\")\n",
        "        else:\n",
        "            print(\"⚠️ GPU not found. Using CPU.\")\n",
        "            return torch.device(\"cpu\")\n",
        "\n",
        "    def print_summary(self):\n",
        "        print(f\"Using device: {self.DEVICE}\")\n",
        "        print(f\"Experiment: {self.EXPERIMENT_NAME}\")\n",
        "        print(f\"Include augmented images: {self.IMG_AUGMENT}\")\n",
        "        print(f\"Classes to train ({self.NUM_CLASSES}): {', '.join(self.CLASSES_TO_USE)}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. Data Preparation Functions\n",
        "# ==========================================\n",
        "def setup_dataset(config):\n",
        "    \"\"\"\n",
        "    Downloads dataset via Kaggle API.\n",
        "    CRITICAL: Checks for kaggle.json AND sets environment variables\n",
        "    BEFORE importing the kaggle library to prevent crashes.\n",
        "    \"\"\"\n",
        "    cwd = os.getcwd()\n",
        "    kaggle_json_path = os.path.join(cwd, \"kaggle.json\")\n",
        "    is_colab = 'google.colab' in sys.modules\n",
        "\n",
        "    # --- 1. PRE-IMPORT CONFIGURATION (Avoids OSError) ---\n",
        "    print(\"Checking for 'kaggle.json'...\")\n",
        "\n",
        "    if os.path.exists(kaggle_json_path):\n",
        "        print(f\"✅ Found 'kaggle.json' in current directory.\")\n",
        "\n",
        "    elif is_colab:\n",
        "        print(\"⚠️ 'kaggle.json' not found. Please upload it now:\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if \"kaggle.json\" in uploaded:\n",
        "            print(\"✅ Upload successful.\")\n",
        "            # Fix permissions (required by Kaggle API)\n",
        "            os.chmod(kaggle_json_path, 0o600)\n",
        "        else:\n",
        "            print(\"❌ Upload failed or cancelled. Exiting setup.\")\n",
        "            return\n",
        "    else:\n",
        "        print(f\"❌ 'kaggle.json' not found in {cwd}\")\n",
        "        print(\"   Please place the file here and run again.\")\n",
        "        return\n",
        "\n",
        "    # Set the environment variable so Kaggle knows where to look\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = cwd\n",
        "\n",
        "    # --- 2. Install/Import Kaggle ---\n",
        "    # Now that env var is set, it is safe to import/install\n",
        "    try:\n",
        "        import kaggle\n",
        "    except ImportError:\n",
        "        print(\"Installing Kaggle API...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n",
        "        import kaggle\n",
        "    except OSError as e:\n",
        "        print(f\"⚠️ Warning: Kaggle import had an issue: {e}\")\n",
        "        print(\"Attempting to proceed with CLI subprocess...\")\n",
        "\n",
        "    # --- 3. Download Dataset ---\n",
        "    if not os.path.exists(config.DATASET_FOLDER_PATH):\n",
        "        print(f\"Dataset folder '{config.DATASET_FOLDER_PATH}' not found. Downloading...\")\n",
        "        try:\n",
        "            # Using subprocess is often more robust than the python API for simple downloads\n",
        "            subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"yudhaislamisulistya/plants-type-datasets\"], check=True)\n",
        "\n",
        "            print(\"Unzipping dataset...\")\n",
        "            import zipfile\n",
        "            with zipfile.ZipFile(\"plants-type-datasets.zip\", 'r') as zip_ref:\n",
        "                zip_ref.extractall(\".\")\n",
        "            print(\"Dataset downloaded and unzipped successfully.\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"❌ Error downloading dataset: {e}\")\n",
        "            print(\"Check your API token and internet connection.\")\n",
        "    else:\n",
        "        print(\"Dataset folder already exists. Skipping download.\")\n",
        "\n",
        "def create_filtered_subsets(config):\n",
        "    \"\"\"Creates a filtered subset of the data based on configuration.\"\"\"\n",
        "    if os.path.exists(config.BASE_FILTERED_DIR):\n",
        "        print(f\"Removing existing filtered data directory: {config.BASE_FILTERED_DIR}\")\n",
        "        shutil.rmtree(config.BASE_FILTERED_DIR)\n",
        "\n",
        "    class_to_idx = {name: i for i, name in enumerate(config.CLASSES_TO_USE)}\n",
        "\n",
        "    # Helper to process directories\n",
        "    def process_split(src_base, dst_base, is_train=False):\n",
        "        if not os.path.exists(src_base):\n",
        "             print(f\"⚠️ Warning: Source directory {src_base} does not exist. Skipping.\")\n",
        "             return\n",
        "\n",
        "        print(f\"Creating filtered set at: {dst_base}...\")\n",
        "        for class_name in config.CLASSES_TO_USE:\n",
        "            src_dir = os.path.join(src_base, class_name)\n",
        "            dst_dir = os.path.join(dst_base, class_name)\n",
        "            os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "            if not os.path.exists(src_dir):\n",
        "                continue\n",
        "\n",
        "            all_images = glob.glob(os.path.join(src_dir, '*.*'))\n",
        "\n",
        "            # Filter based on augmentation setting\n",
        "            if config.IMG_AUGMENT:\n",
        "                # Take all images (augmented and original)\n",
        "                imgs = all_images\n",
        "            else:\n",
        "                # Take only original images\n",
        "                imgs = [img for img in all_images if not os.path.basename(img).startswith('aug_')]\n",
        "\n",
        "            # Apply limit for training set\n",
        "            if is_train:\n",
        "                imgs = imgs[:config.MAX_IMAGES_PER_CLASS_TRAIN]\n",
        "\n",
        "            for img_path in imgs:\n",
        "                shutil.copy(img_path, dst_dir)\n",
        "\n",
        "    process_split(config.BASE_TRAIN_DIR, config.FILTERED_TRAIN_DIR, is_train=True)\n",
        "    process_split(config.BASE_VAL_DIR, config.FILTERED_VAL_DIR)\n",
        "    process_split(config.BASE_TEST_DIR, config.FILTERED_TEST_DIR)\n",
        "\n",
        "    with open(config.CLASS_MAP_PATH, 'w') as f:\n",
        "        json.dump(class_to_idx, f)\n",
        "    print(f\"Class mapping saved to {config.CLASS_MAP_PATH}\")\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Creates DataLoaders for train, val, and test.\"\"\"\n",
        "    imgnet_mean = [0.485, 0.456, 0.406]\n",
        "    imgnet_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(config.IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=imgnet_mean, std=imgnet_std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(config.IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=imgnet_mean, std=imgnet_std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(config.IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=imgnet_mean, std=imgnet_std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # Ensure directories exist before creating ImageFolder\n",
        "    if not os.path.exists(config.FILTERED_TRAIN_DIR):\n",
        "        print(\"Filtered training directory missing. Cannot create dataloaders.\")\n",
        "        return None, None\n",
        "\n",
        "    image_datasets = {\n",
        "        'train': datasets.ImageFolder(config.FILTERED_TRAIN_DIR, data_transforms['train']),\n",
        "        'val': datasets.ImageFolder(config.FILTERED_VAL_DIR, data_transforms['val']),\n",
        "        'test': datasets.ImageFolder(config.FILTERED_TEST_DIR, data_transforms['test'])\n",
        "    }\n",
        "\n",
        "    # Pin memory helps with GPU transfer speed (CUDA/ROCm)\n",
        "    use_pin_memory = (config.DEVICE.type == 'cuda')\n",
        "    # Num workers: 2 is usually safe, set higher locally if you have more cores\n",
        "    num_workers = 2 if os.cpu_count() is None else min(4, os.cpu_count())\n",
        "\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(image_datasets['train'], batch_size=config.BATCH_SIZE, shuffle=config.SHUFFLE_TRAINING, pin_memory=use_pin_memory, num_workers=num_workers),\n",
        "        'val': DataLoader(image_datasets['val'], batch_size=config.BATCH_SIZE, shuffle=False, pin_memory=use_pin_memory, num_workers=num_workers),\n",
        "        'test': DataLoader(image_datasets['test'], batch_size=config.BATCH_SIZE, shuffle=False, pin_memory=use_pin_memory, num_workers=num_workers)\n",
        "    }\n",
        "\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "\n",
        "    print(f\"Data Loaded: Train({dataset_sizes['train']}), Val({dataset_sizes['val']}), Test({dataset_sizes['test']})\")\n",
        "    return dataloaders, dataset_sizes\n",
        "\n",
        "# ==========================================\n",
        "# 3. Model & Training Functions\n",
        "# ==========================================\n",
        "def build_model(config):\n",
        "    \"\"\"Initializes ResNet50 with frozen layers and custom head.\"\"\"\n",
        "    print(\"Building model...\")\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, config.NUM_CLASSES)\n",
        "    model = model.to(config.DEVICE)\n",
        "    return model\n",
        "\n",
        "def train_model(config, model, dataloaders, dataset_sizes):\n",
        "    \"\"\"Runs the training loop.\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.fc.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    history = {\"loss\": [], \"accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{config.EPOCHS} ---\")\n",
        "\n",
        "        # --- Training Phase ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        progress_bar = tqdm(dataloaders['train'], desc=\"[Train]\")\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(config.DEVICE), labels.to(config.DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            progress_bar.set_postfix(batch_loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['train']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_running_corrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            progress_bar_val = tqdm(dataloaders['val'], desc=\"[Validate]\")\n",
        "            for inputs, labels in progress_bar_val:\n",
        "                inputs, labels = inputs.to(config.DEVICE), labels.to(config.DEVICE)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss = val_running_loss / dataset_sizes['val']\n",
        "        val_acc = val_running_corrects.double() / dataset_sizes['val']\n",
        "\n",
        "        print(f\"  Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
        "\n",
        "        history[\"loss\"].append(epoch_loss)\n",
        "        history[\"accuracy\"].append(epoch_acc.item())\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_accuracy\"].append(val_acc.item())\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "            print(f\"  -> New best model found!\")\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    print(f\"\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "    print(f\"Best Val Acc: {best_val_acc:.4f}\")\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history, best_val_acc\n",
        "\n",
        "# ==========================================\n",
        "# 4. Evaluation & Visualization Functions\n",
        "# ==========================================\n",
        "def evaluate_on_test(config, model, dataloaders, dataset_sizes):\n",
        "    \"\"\"Evaluates the model on the test set.\"\"\"\n",
        "    print(\"--- Running Final Evaluation on Test Set ---\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloaders['test'], desc=\"[Test]\"):\n",
        "            inputs, labels = inputs.to(config.DEVICE), labels.to(config.DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            test_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    final_loss = test_loss / dataset_sizes['test']\n",
        "    final_acc = test_corrects.double() / dataset_sizes['test']\n",
        "\n",
        "    print(f\"\\nTest Results -> Loss: {final_loss:.4f} | Acc: {final_acc:.4f}\")\n",
        "    return float(final_loss), float(final_acc)\n",
        "\n",
        "def save_history(config, history, best_val_acc, test_loss, test_acc):\n",
        "    \"\"\"Saves training history to JSON.\"\"\"\n",
        "    history_data = {\n",
        "        'loss': [float(x) for x in history['loss']],\n",
        "        'accuracy': [float(x) for x in history['accuracy']],\n",
        "        'val_loss': [float(x) for x in history['val_loss']],\n",
        "        'val_accuracy': [float(x) for x in history['val_accuracy']],\n",
        "        'experiment_name': config.EXPERIMENT_NAME,\n",
        "        'img_augment': config.IMG_AUGMENT,\n",
        "        'epochs': config.EPOCHS,\n",
        "        'best_val_acc': float(best_val_acc),\n",
        "        'test_loss': test_loss,\n",
        "        'test_accuracy': test_acc\n",
        "    }\n",
        "\n",
        "    with open(config.HISTORY_SAVE_PATH, 'w') as f:\n",
        "        json.dump(history_data, f, indent=2)\n",
        "    print(f\"History saved to {config.HISTORY_SAVE_PATH}\")\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    \"\"\"Plots accuracy and loss curves.\"\"\"\n",
        "    epochs = range(1, len(history['accuracy']) + 1)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['accuracy'], label='Train')\n",
        "    plt.plot(epochs, history['val_accuracy'], label='Val')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['loss'], label='Train')\n",
        "    plt.plot(epochs, history['val_loss'], label='Val')\n",
        "    plt.title('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix_vis(config, model, dataloaders):\n",
        "    \"\"\"Generates and plots the confusion matrix.\"\"\"\n",
        "    model.eval()\n",
        "    y_true_all = []\n",
        "    y_pred_all = []\n",
        "\n",
        "    print(\"Generating Confusion Matrix...\")\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            inputs = inputs.to(config.DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            y_true_all.extend(labels.cpu().numpy())\n",
        "            y_pred_all.extend(preds.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(y_true_all, y_pred_all)\n",
        "\n",
        "    # Normalize\n",
        "    with np.errstate(all='ignore'):\n",
        "        cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "        cm_norm = np.nan_to_num(cm_norm)\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(14, 12))\n",
        "    im = ax.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "    ax.set(xticks=np.arange(config.NUM_CLASSES),\n",
        "           yticks=np.arange(config.NUM_CLASSES),\n",
        "           xticklabels=config.CLASSES_TO_USE,\n",
        "           yticklabels=config.CLASSES_TO_USE,\n",
        "           title='Normalized Confusion Matrix',\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def compare_experiments():\n",
        "    \"\"\"Compares baseline and augmented history files if both exist.\"\"\"\n",
        "    base_path = './history_baseline_no_augmented_images.json'\n",
        "    aug_path = './history_with_augmented_images.json'\n",
        "\n",
        "    if os.path.exists(base_path) and os.path.exists(aug_path):\n",
        "        print(\"\\n--- Comparative Analysis ---\")\n",
        "        try:\n",
        "            with open(base_path) as f: h_base = json.load(f)\n",
        "            with open(aug_path) as f: h_aug = json.load(f)\n",
        "\n",
        "            print(f\"Baseline Test Acc:  {h_base.get('test_accuracy', 0):.4f}\")\n",
        "            print(f\"Augmented Test Acc: {h_aug.get('test_accuracy', 0):.4f}\")\n",
        "\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            plt.bar(['Baseline', 'Augmented'],\n",
        "                    [h_base.get('test_accuracy', 0), h_aug.get('test_accuracy', 0)],\n",
        "                    color=['blue', 'orange'])\n",
        "            plt.title('Test Accuracy Comparison')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load comparisons: {e}\")\n",
        "    else:\n",
        "        print(\"\\nSkipping comparison (run both experiment types to enable).\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. Main Execution\n",
        "# ==========================================\n",
        "def main():\n",
        "    # 1. Initialize Configuration\n",
        "    cfg = Config()\n",
        "    cfg.print_summary()\n",
        "\n",
        "    # 2. Setup Data\n",
        "    setup_dataset(cfg)\n",
        "    create_filtered_subsets(cfg)\n",
        "    dataloaders, dataset_sizes = get_dataloaders(cfg)\n",
        "\n",
        "    if dataloaders is None:\n",
        "        print(\"❌ Error: Data not available. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # 3. Initialize Model\n",
        "    model = build_model(cfg)\n",
        "\n",
        "    # 4. Train\n",
        "    model, history, best_val_acc = train_model(cfg, model, dataloaders, dataset_sizes)\n",
        "\n",
        "    # 5. Save Model\n",
        "    torch.save(model.state_dict(), cfg.MODEL_SAVE_PATH)\n",
        "    print(f\"Best model saved to {cfg.MODEL_SAVE_PATH}\")\n",
        "\n",
        "    # 6. Final Evaluation\n",
        "    test_loss, test_acc = evaluate_on_test(cfg, model, dataloaders, dataset_sizes)\n",
        "\n",
        "    # 7. Save History\n",
        "    save_history(cfg, history, best_val_acc, test_loss, test_acc)\n",
        "\n",
        "    # 8. Visualization\n",
        "    plot_training_curves(history)\n",
        "    plot_confusion_matrix_vis(cfg, model, dataloaders)\n",
        "\n",
        "    # 9. Comparison (Optional)\n",
        "    compare_experiments()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "    # main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec6d40c8"
      },
      "source": [
        "### Initialize Configuration\n",
        "\n",
        "This step sets up all the parameters for the experiment, including dataset paths, hyperparameters, and experiment names. It then prints a summary of the configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f74600c"
      },
      "source": [
        "cfg = Config()\n",
        "cfg.print_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d3f7aa1"
      },
      "source": [
        "### Setup Data\n",
        "\n",
        "This sequence of steps downloads the dataset (if not present), creates filtered subsets based on the configuration (e.g., with or without augmented images, and a limited number of training images per class), and then prepares the data loaders for training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d952a216"
      },
      "source": [
        "setup_dataset(cfg)\n",
        "create_filtered_subsets(cfg)\n",
        "dataloaders, dataset_sizes = get_dataloaders(cfg)\n",
        "\n",
        "if dataloaders is None:\n",
        "    print(\"❌ Error: Data not available. Exiting.\")\n",
        "else:\n",
        "    print(\"Data setup complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78b1c78"
      },
      "source": [
        "### Initialize Model\n",
        "\n",
        "This step builds the ResNet50 model, freezes its convolutional layers, and adds a new classification head suitable for the number of classes in the dataset. The model is then moved to the specified device (GPU/CPU)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2d9774"
      },
      "source": [
        "model = build_model(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba70095a"
      },
      "source": [
        "### Train Model\n",
        "\n",
        "This initiates the training loop for the model using the defined criterion (loss function) and optimizer. It tracks training and validation loss/accuracy across epochs and saves the best model weights based on validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a312b04"
      },
      "source": [
        "model, history, best_val_acc = train_model(cfg, model, dataloaders, dataset_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f563a841"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "The weights of the best performing model (based on validation accuracy) are saved to a file for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f8ed248"
      },
      "source": [
        "torch.save(model.state_dict(), cfg.MODEL_SAVE_PATH)\n",
        "print(f\"Best model saved to {cfg.MODEL_SAVE_PATH}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8616f6e"
      },
      "source": [
        "### Final Evaluation\n",
        "\n",
        "The trained model is evaluated on the unseen test set to determine its generalization performance, providing final loss and accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bffe55c9"
      },
      "source": [
        "test_loss, test_acc = evaluate_on_test(cfg, model, dataloaders, dataset_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea8b9d3d"
      },
      "source": [
        "### Save History\n",
        "\n",
        "All training and evaluation metrics, including losses, accuracies, and configuration details, are saved to a JSON file for record-keeping and future analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6a0c5e8"
      },
      "source": [
        "save_history(cfg, history, best_val_acc, test_loss, test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35353293"
      },
      "source": [
        "### Visualization\n",
        "\n",
        "This step generates and displays plots for the training and validation accuracy/loss curves, and a normalized confusion matrix to visualize model performance per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e05d81f"
      },
      "source": [
        "plot_training_curves(history)\n",
        "plot_confusion_matrix_vis(cfg, model, dataloaders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caf22174"
      },
      "source": [
        "### Compare Experiments (Optional)\n",
        "\n",
        "If multiple experiment histories are saved (e.g., baseline vs. augmented), this step loads them and provides a comparative analysis of their test accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5d68602"
      },
      "source": [
        "compare_experiments()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}